{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b843d8ce-3a32-43b3-ac0b-0aa1e1f53df8",
   "metadata": {},
   "source": [
    "## **Set Biobliometric Data for Scopus**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50317c9-b4f2-4751-9caa-cf29f1a80639",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2831a-93ee-4549-bc33-98b48c57c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c87f2e-d95a-43f2-9262-87aa92e53c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir ruta del archivo\n",
    "input_csv = 'Search_criteria/scopus_MFC_Bibliometric.csv' \n",
    "\n",
    "def clean_scopus_data(input_csv, scopus_cleaned):\n",
    "    # Cargar datos\n",
    "    df = pd.read_csv(input_csv, encoding='utf-8')\n",
    "    \n",
    "    # Normalizar nombres de columnas para evitar errores\n",
    "    #df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    \n",
    "    # Eliminar duplicados basados en t√≠tulo y DOI\n",
    "    df = df.drop_duplicates(subset=['Title', 'DOI'], keep='first')\n",
    "    \n",
    "    # Eliminar registros sin t√≠tulo, DOI o palabras clave del autor\n",
    "    df = df.dropna(subset=['Title', 'DOI', 'Author Keywords', 'Index Keywords' ])\n",
    "    \n",
    "    # Funci√≥n para limpiar texto dentro de <>\n",
    "    def clean_text(text):\n",
    "        return re.sub(r'<.*?>', '', str(text))\n",
    "    \n",
    "    # Aplicar limpieza a todas las columnas de texto\n",
    "    df = df.applymap(lambda x: clean_text(x) if isinstance(x, str) else x)\n",
    "        \n",
    "    # Guardar CSV limpio\n",
    "    df.to_csv(scopus_cleaned, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Datos limpios guardados en {scopus_cleaned} con {len(df)} registros.\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# clean_scopus_data('scopus_raw.csv', 'scopus_cleaned.csv', start_year=2015)\n",
    "clean_scopus_data(input_csv,'Search_criteria/scopus_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552ec63-1bfe-4a47-9c2e-386c0a30b9d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Modify Data for Bibliometrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cbc82-c01d-40fe-a1b6-671ab48e509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaned data\n",
    "archivo_csv = 'Search_criteria/scopus_cleaned.csv'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Verificar si la columna \"JI\" existe, si no, agregarla vac√≠a\n",
    "if \"JI\" not in df.columns:\n",
    "    df[\"JI\"] = \"\"\n",
    "\n",
    "# Verificar si la columna \"WC\" existe, si no, agregarla vac√≠a\n",
    "if \"WC\" not in df.columns:\n",
    "    df[\"WC\"] = \"\"\n",
    "\n",
    "# üîπ Renombrar columnas a las esperadas por Biblioshiny\n",
    "columnas_esperadas = {\n",
    "    \"Authors\": \"AU\",\n",
    "    \"Title\": \"TI\",\n",
    "    \"DOI\": \"DI\",\n",
    "    \"Source title\": \"SO\",\n",
    "    \"Year\": \"PY\",\n",
    "    \"Cited by\": \"TC\",\n",
    "    \"Affiliations\": \"C1\",\n",
    "    \"Author Keywords\": \"DE\",\n",
    "    \"Index Keywords\": \"ID\",\n",
    "    \"Abstract\": \"AB\",\n",
    "    \"Correspondence Address\": \"RP\",\n",
    "    \"References\": \"CR\"\n",
    "}\n",
    "\n",
    "# Solo renombrar si las columnas existen en el archivo\n",
    "df.rename(columns={col: columnas_esperadas[col] for col in df.columns if col in columnas_esperadas}, inplace=True)\n",
    "\n",
    "# üîπ Guardar el nuevo archivo en el formato correcto\n",
    "archivo_salida = \"Search_criteria/formateado_biblioshiny.csv\"\n",
    "df.to_csv(archivo_salida, index=False)\n",
    "\n",
    "print(f\"‚úÖ Archivo formateado guardado como: {archivo_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67ed00-76e6-4db2-a0ce-08c5542f4603",
   "metadata": {},
   "source": [
    "### Extract countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66bf85-b835-47b2-ab6b-f3b8422f446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "archivo_csv = 'Search_criteria/formateado_biblioshiny.csv'\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "\n",
    "# Funci√≥n para extraer los pa√≠ses de la columna \"C1\"\n",
    "def extract_countries(affiliations):\n",
    "    if pd.isna(affiliations):\n",
    "        return []\n",
    "    # Suponiendo que los pa√≠ses est√°n al final de cada afiliaci√≥n, separados por comas\n",
    "    countries = re.findall(r',\\s*([A-Za-z\\s]+)$', affiliations, re.MULTILINE)\n",
    "    return countries\n",
    "\n",
    "# Aplicar la funci√≥n para extraer pa√≠ses\n",
    "df[\"Countries\"] = df[\"C1\"].apply(extract_countries)\n",
    "\n",
    "# Seleccionar solo las columnas de autores y pa√≠ses\n",
    "df_countries = df[[\"AU\", \"Countries\"]]\n",
    "\n",
    "# Mostrar algunas filas del resultado\n",
    "#df_countries.head()\n",
    "\n",
    "df.to_csv('df_countries.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
